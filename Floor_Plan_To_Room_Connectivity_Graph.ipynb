{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "s-5y7P6GC2_n"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALL LIBRARY"
      ],
      "metadata": {
        "id": "S48BfI8p-DlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instructor openai graphviz pydantic networkx plotly gradio -q"
      ],
      "metadata": {
        "id": "R_Db2sbjcVsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Setup"
      ],
      "metadata": {
        "id": "Y6GZ9DjU9zc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using OpenAI"
      ],
      "metadata": {
        "id": "s-5y7P6GC2_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Approach 1 :  OpenAI Key\n",
        "\n",
        "'''\n",
        "import instructor\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_key = \"insert_your_key_here\"\n",
        "\n",
        "client = OpenAI(\n",
        " api_key=openai_key,\n",
        " )\n",
        "\n",
        "model_id = \"gpt-4o-mini\"\n",
        "client = instructor.from_openai(client)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "kIjVQO7I-MLY",
        "outputId": "ed3fa92d-2580-4156-80dc-c54f3e603fea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport instructor\\nfrom openai import OpenAI\\n\\nopenai_key = \"insert_your_key_here\"\\n\\nclient = OpenAI(\\n api_key=openai_key,\\n )\\n\\nmodel_id = \"gpt-4o-mini\"\\nclient = instructor.from_openai(client)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Azure OpenAI"
      ],
      "metadata": {
        "id": "GYugv-YuC5oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Approach 2 :  AzureOpenAI Key\n",
        "import instructor\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "azure_endpoint = \"your_azure_endpoint\"\n",
        "azure_api_key = \"your_azure_key\"\n",
        "\n",
        "az_client = AzureOpenAI(\n",
        "    azure_endpoint = azure_endpoint,\n",
        "    api_key=azure_api_key,\n",
        "    api_version=\"2024-02-15-preview\"\n",
        ")\n",
        "\n",
        "model_id = \"your_model_id\"\n",
        "\n",
        "client = instructor.from_openai(az_client)\n"
      ],
      "metadata": {
        "id": "6ERQ4BIdci9_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORFLOW LOGIC"
      ],
      "metadata": {
        "id": "hck8JtJm-AMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "import base64\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from PIL import Image\n",
        "import os\n",
        "import logging\n",
        "import traceback\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Pydantic Structured models\n",
        "\n",
        "class Node(BaseModel):\n",
        "    id: int\n",
        "    label: str\n",
        "    color: str\n",
        "\n",
        "class Edge(BaseModel):\n",
        "    source: int\n",
        "    target: int\n",
        "    label: str\n",
        "    color: str = \"black\"\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    nodes: list[Node] = Field(..., default_factory=list)\n",
        "    edges: list[Edge] = Field(..., default_factory=list)\n",
        "\n",
        "# image encoding logic\n",
        "def encode_image(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error encoding image: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# graph visualiztion function\n",
        "\n",
        "def visualize_graph(graph):\n",
        "    try:\n",
        "        G = nx.DiGraph()\n",
        "\n",
        "        for node in graph.nodes:\n",
        "            G.add_node(node.id, label=node.label, color=node.color)\n",
        "\n",
        "        for edge in graph.edges:\n",
        "            G.add_edge(edge.source, edge.target, label=edge.label, color=edge.color)\n",
        "\n",
        "        pos = nx.spring_layout(G, k=0.9, iterations=50)\n",
        "\n",
        "        plt.figure(figsize=(14, 10))\n",
        "        plt.title(\"Enhanced Home Layout Visualization\", fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Enhance node appearance\n",
        "        node_colors = [mcolors.to_rgba(node[1]['color'], alpha=0.8) for node in G.nodes(data=True)]\n",
        "        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=3000, edgecolors='gray', linewidths=2)\n",
        "\n",
        "        # Improve label rendering\n",
        "        labels = {node[0]: node[1]['label'] for node in G.nodes(data=True)}\n",
        "        nx.draw_networkx_labels(G, pos, labels, font_size=10, font_weight='bold')\n",
        "\n",
        "        # Enhance edge appearance\n",
        "        edge_colors = [mcolors.to_rgba(edge[2]['color'], alpha=0.6) for edge in G.edges(data=True)]\n",
        "        nx.draw_networkx_edges(G, pos, edge_color=edge_colors, width=2, arrowsize=20)\n",
        "\n",
        "        # Improve edge label rendering\n",
        "        edge_labels = {(u, v): d['label'] for u, v, d in G.edges(data=True)}\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, font_color='darkblue')\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Create a color to room type mapping\n",
        "        color_to_room = {}\n",
        "        for node in G.nodes(data=True):\n",
        "            color = node[1]['color']\n",
        "            room = node[1]['label']\n",
        "            if color not in color_to_room:\n",
        "                color_to_room[color] = room\n",
        "\n",
        "        # Add a legend with color names and corresponding room types\n",
        "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w',\n",
        "                           label=f\"{color}: {room}\",\n",
        "                           markerfacecolor=color, markersize=10)\n",
        "                           for color, room in color_to_room.items()]\n",
        "        plt.legend(handles=legend_elements, title=\"Room Types\", loc='best', fontsize=8)\n",
        "\n",
        "        # Save the image with higher DPI\n",
        "        img_buf = io.BytesIO()\n",
        "        plt.savefig(img_buf, format='png', dpi=300, bbox_inches='tight')\n",
        "        img_buf.seek(0)\n",
        "        return Image.open(img_buf)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error visualizing graph: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def generate_graph(image_path) -> KnowledgeGraph:\n",
        "    try:\n",
        "        # Encode the image\n",
        "        base64_image = encode_image(image_path)\n",
        "\n",
        "        logger.info(\"Sending request to OpenAI API\")\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_id,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Describe the relationship between rooms, windows and doors openings and connectivity. Start from the entrance and describe the layout as if you are giving a walking tour of the layout. Output a array of nodes(id, label, color) and the edges(source, target, label). Help me understand the following image by describing it as a detailed knowledge graph:\"},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "            response_model=KnowledgeGraph,\n",
        "        )\n",
        "        logger.info(\"Received response from OpenAI API\")\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating graph: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def process_image(input_image):\n",
        "    try:\n",
        "        logger.info(f\"Processing image: {input_image}\")\n",
        "        graph = generate_graph(input_image)\n",
        "        output_image = visualize_graph(graph)\n",
        "        return output_image\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in process_image: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=process_image,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Image to Knowledge Graph\",\n",
        "    description=\"Upload an image to generate a knowledge graph representation.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        iface.launch()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error launching Gradio interface: {str(e)}\")\n",
        "        logger.error(traceback.format_exc())"
      ],
      "metadata": {
        "id": "kfTyph4H8ERg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}